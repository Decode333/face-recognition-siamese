{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhGqRYlgRGLDeOPUHP8yny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Decode333/face-recognition-siamese/blob/main/face_recognition_siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import os\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import random"
      ],
      "metadata": {
        "id": "5otqoniOA-RI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder_path, image_size=(100, 100)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for person_name in os.listdir(folder_path):\n",
        "        person_folder = os.path.join(folder_path, person_name)\n",
        "        if not os.path.isdir(person_folder):\n",
        "            continue\n",
        "        for img_name in os.listdir(person_folder):\n",
        "            img_path = os.path.join(person_folder, img_name)\n",
        "            img = load_img(img_path, target_size=image_size)\n",
        "            img = img_to_array(img) / 255.0\n",
        "            images.append(img)\n",
        "            labels.append(person_name)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "X6ZngMlFBXxT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pairs(images, labels):\n",
        "    pair_images = []\n",
        "    pair_labels = []\n",
        "\n",
        "    # Get unique class labels\n",
        "    unique_labels = np.unique(labels)\n",
        "\n",
        "    label_to_indices = {label: np.where(labels == label)[0] for label in unique_labels}\n",
        "\n",
        "    for idx, img in enumerate(images):\n",
        "        current_label = labels[idx]\n",
        "        pos_idx = idx\n",
        "        while pos_idx == idx:\n",
        "            pos_idx = random.choice(label_to_indices[current_label])\n",
        "\n",
        "        neg_label = random.choice(unique_labels[unique_labels != current_label])\n",
        "        neg_idx = random.choice(label_to_indices[neg_label])\n",
        "\n",
        "        # Positive pair\n",
        "        pair_images.append([img, images[pos_idx]])\n",
        "        pair_labels.append(1)\n",
        "\n",
        "        # Negative pair\n",
        "        pair_images.append([img, images[neg_idx]])\n",
        "        pair_labels.append(0)\n",
        "\n",
        "    return np.array(pair_images), np.array(pair_labels)"
      ],
      "metadata": {
        "id": "iKivURddBW1x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load and prepare dataset ---\n",
        "data_folder = \"dataset\"  # Change if your dataset folder is different\n",
        "images, labels = load_images_from_folder(data_folder)\n",
        "pair_images, pair_labels = create_pairs(images, labels)"
      ],
      "metadata": {
        "id": "7eYcJChUA-Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and validation sets\n",
        "split_idx = int(0.8 * len(pair_images))\n",
        "trainX, testX = pair_images[:split_idx], pair_images[split_idx:]\n",
        "trainY, testY = pair_labels[:split_idx], pair_labels[split_idx:]"
      ],
      "metadata": {
        "id": "JU9Gme2-A-Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_siamese_network(input_shape=(100, 100, 3)):\n",
        "    embedding_model = build_embedding_model(input_shape)\n",
        "\n",
        "    input_a = layers.Input(shape=input_shape)\n",
        "    input_b = layers.Input(shape=input_shape)\n",
        "\n",
        "    emb_a = embedding_model(input_a)\n",
        "    emb_b = embedding_model(input_b)\n",
        "\n",
        "    distance = layers.Lambda(lambda tensors: tf.math.abs(tensors[0] - tensors[1]))([emb_a, emb_b])\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(distance)\n",
        "\n",
        "    siamese_model = Model([input_a, input_b], outputs)\n",
        "\n",
        "    return siamese_model\n",
        "\n",
        "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    \"\"\"\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    square_pred = tf.math.square(y_pred)\n",
        "    margin_square = tf.math.square(tf.math.maximum(margin - y_pred, 0))\n",
        "    return tf.math.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)"
      ],
      "metadata": {
        "id": "4kMEw-5HB077"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build Siamese model ---\n",
        "input_shape = images.shape[1:]\n",
        "model = build_siamese_network(input_shape)\n",
        "model.compile(loss=contrastive_loss, optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "l9tLeWGQA-IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train the model ---\n",
        "history = model.fit(\n",
        "    [trainX[:, 0], trainX[:, 1]],\n",
        "    trainY,\n",
        "    validation_data=([testX[:, 0], testX[:, 1]], testY),\n",
        "    batch_size=32,\n",
        "    epochs=20\n",
        ")"
      ],
      "metadata": {
        "id": "jO7pXnkIA-Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save the entire model ---\n",
        "model.save(\"siamese_model.h5\")"
      ],
      "metadata": {
        "id": "AvtOyIyLA-Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save the embeddings for known faces ---\n",
        "embedding_model = model.get_layer('Embedding')\n",
        "known_embeddings = []\n",
        "known_names = []\n",
        "\n",
        "# Create known database\n",
        "for label in np.unique(labels):\n",
        "    person_indices = np.where(labels == label)[0]\n",
        "    person_img = images[person_indices[0]]  # Take one image per person\n",
        "    person_img = np.expand_dims(person_img, axis=0)\n",
        "    emb = embedding_model.predict(person_img)[0]\n",
        "    known_embeddings.append(emb)\n",
        "    known_names.append(label)\n",
        "\n",
        "# Save to pickle\n",
        "with open(\"embeddings.pickle\", \"wb\") as f:\n",
        "    pickle.dump({\"embeddings\": known_embeddings, \"names\": known_names}, f)"
      ],
      "metadata": {
        "id": "TnMsKRrNA-BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pahF1A9SA9u7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}